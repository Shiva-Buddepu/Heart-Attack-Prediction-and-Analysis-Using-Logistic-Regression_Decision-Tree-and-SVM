# -*- coding: utf-8 -*-
"""Heart Attack Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCGfh7ZU3-0Os-TEKsPXlW9bxKKwnT-R

##Import all required modules
"""

# Commented out IPython magic to ensure Python compatibility.
import pylab as pl
import numpy as np
import pandas as pd
import seaborn as sns
import scipy.optimize as opt
import scipy.stats as stats
import matplotlib.pyplot as plt
from scipy.stats import randint
# %matplotlib inline

import warnings
warnings.simplefilter("ignore")

"""##Load data"""

ha_df = pd.read_csv('heart.csv')
ha_df.head()

ha_df.columns

# value checking
ha_df.info()

# from the data understanding we got
categoric_cols = ['sex', 'cp', 'fbs', 'restecg',
                  'exng', 'slp', 'caa', 'thall']

for i in categoric_cols:
     print('all value in column {0} : \n{1}'.format(i, ha_df[i].value_counts().sort_index()))
     print('\n')

"""##Outliers"""

#Plotting Boxplot
col_num = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']
plt.figure(figsize=(10,5))
for i in range(0,len(col_num)):
    plt.subplot(1,len(col_num),i+1)
    sns.boxplot(y=ha_df[col_num[i]])
    plt.tight_layout()

for i in col_num:
    Q1 = ha_df[i].quantile(0.25)
    Q3 = ha_df[i].quantile(0.75)
    IQR = Q3-Q1
    LowerBound = Q1 - (1.5 * IQR)
    UpperBound = Q3 + (1.5 * IQR)

    ha_df = ha_df[(ha_df[i] >= LowerBound)&(ha_df[i] <= UpperBound)]

col_num = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']
plt.figure(figsize=(10,5))
for i in range(0,len(col_num)):
    plt.subplot(1,len(col_num),i+1)
    sns.boxplot(y = ha_df[col_num[i]])
    plt.tight_layout()

ha_df.shape

"""##Missing value"""

ha_df.isna().sum()

"""##Duplicate data"""

ha_df.duplicated().sum()

ha_df = ha_df.drop_duplicates()

ha_df.duplicated().sum()

"""##Exploratory data analysis"""

ha_df[col_num].describe().transpose()

df = ha_df

df.columns

"""##Count plot"""

count = ['sex', 'cp', 'fbs', 'restecg','exng','slp', 'caa', 'thall', 'output']

i = ['age', 'trtbps', 'chol','thalachh','oldpeak']
for j in i:
    plt.hist(df[j],bins = 60, color = 'slateblue')
    plt.title(j)
    plt.show()

"""##Checking for multicollinearity"""

#Calculating Variance Inflation Factor (VIF) to Detect Multicollinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_data = pd.DataFrame()
vif_data['feature'] = df.columns
vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]
pd.set_option('display.max_rows', None)
vif_data.sort_values(by= 'VIF', ascending = False)

df.drop(columns = ['trtbps'], inplace = True)

#Calculating Variance Inflation Factor (VIF) to Detect Multicollinearity
vif_data = pd.DataFrame()
vif_data['feature'] = df.columns
vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]
pd.set_option('display.max_rows', None)
vif_data.sort_values(by= 'VIF', ascending = False)

df.drop(columns = ['thalachh'], inplace = True)

#Calculating Variance Inflation Factor (VIF) to Detect Multicollinearity
vif_data = pd.DataFrame()
vif_data['feature'] = df.columns
vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]
pd.set_option('display.max_rows', None)
vif_data.sort_values(by= 'VIF', ascending = False)

df.drop(columns = ['age'], inplace = True)

#Calculating Variance Inflation Factor (VIF) to Detect Multicollinearity
vif_data = pd.DataFrame()
vif_data['feature'] = df.columns
vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]
pd.set_option('display.max_rows', None)
vif_data.sort_values(by= 'VIF', ascending = False)

df.drop(columns = ['chol'], inplace = True)

#Calculating Variance Inflation Factor (VIF) to Detect Multicollinearity
vif_data = pd.DataFrame()
vif_data['feature'] = df.columns
vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]
pd.set_option('display.max_rows', None)
vif_data.sort_values(by= 'VIF', ascending = False)

df.columns

#Feature Selection Using Pearson Correlation Coefficient
print('Pearson Correlation,')
plt.figure(figsize = (11,11))
cor = df.corr().iloc[:,-1:]
sns.heatmap(cor, annot = True, cmap = plt.cm.Blues)
plt.show()

print('abs corr score: ')
print(abs(cor['output'][0:-1]))
cor['output'] = cor['output'][0:-1]
margin = abs(cor['output'][0:-1]).mean()

print('\n')

print('mean {0}'.format(margin))

print('\n')

print('feature selection result: ')
fs = abs(cor['output'][0:-1])[abs(cor['output']) > margin]
print(fs)

df = df.drop(columns = ['sex', 'fbs', 'restecg', 'slp'])

df.columns

df.head()

"""##train test split"""

X = df.drop(columns=['output'])
y = df['output']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""##hypertuning"""

from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

model_params = {
    'Logistic_Regression': {
        'model': LogisticRegression(),
        'params' : {
            'penalty':['l1', 'l2', 'elasticnet', 'none'],
            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],
            'multi_class': ['auto', 'ovr', 'multinomial'],
        }
    },
    'decision_tree':{
        'model':DecisionTreeClassifier(),
        'params':{
            'splitter':['best','random'],
            'max_features': ['auto', 'sqrt', 'log2'],
            'max_depth' : [4,5,6,7,8],
            'criterion' :['gini', 'entropy']
        }
    },
    'SVM_Classifier':{
        'model' : SVC(),
        'params':{
            'kernel' : ['rbf','poly','sigmoid','linear'],
            'gamma' : ['scale','auto'],
        }
    }
    }
scores = []

from sklearn.model_selection import GridSearchCV
for model_name, mp in model_params.items():
    clf =  GridSearchCV(mp['model'], mp['params'], cv=3, return_train_score=False)
    clf.fit(X_train,y_train)
    scores.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
best = pd.DataFrame(scores,columns=['model','best_score','best_params'])
best

"""#Model fitting

##Logistic Regression
"""

#perform model hypertuning
best.best_params[0]

#model fitting
model = LogisticRegression(solver = 'saga',
                           penalty = 'l1',
                           multi_class = 'auto')
model.fit(X_train,y_train)
y_predict = model.predict(X_test)

#Visualizing Model Performance Using Confusion Matrix and Heatmap
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_predict))

import seaborn as sns
sns.heatmap(confusion_matrix(y_test, y_predict), annot = True)
plt.show()

#evaluation
from sklearn.metrics import classification_report
print('\n')
print('Classification Report:')
print(classification_report(y_test, y_predict))

"""##Decision Tree"""

#perform model hypertuning
best.best_params[1]

#model fitting
model = DecisionTreeClassifier(criterion = 'gini',
                               max_depth = 5,
                               max_features = 'log2',
                               splitter = 'best')
model.fit(X_train,y_train)
y_predict = model.predict(X_test)

#Visualizing Model Performance Using Confusion Matrix and Heatmap
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_predict))

import seaborn as sns
sns.heatmap(confusion_matrix(y_test, y_predict), annot = True)
plt.show()

#evaluation
from sklearn.metrics import classification_report
print('\n')
print('Classification Report:')
print(classification_report(y_test, y_predict))

"""##SVM"""

#perform model hypertuning
best.best_params[2]

#model fitting
model = SVC(gamma = 'auto', kernel = 'rbf')
model.fit(X_train,y_train)
y_predict = model.predict(X_test)

#Visualizing Model Performance Using Confusion Matrix and Heatmap
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_predict))

import seaborn as sns
sns.heatmap(confusion_matrix(y_test, y_predict), annot = True)
plt.show()

#evaluation
from sklearn.metrics import classification_report
print('\n')
print('Classification Report:')
print(classification_report(y_test, y_predict))